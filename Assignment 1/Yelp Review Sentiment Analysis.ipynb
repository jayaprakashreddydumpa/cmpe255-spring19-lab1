{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  vkVSCC7xljjrAI4UGfnKEQ  bv2nCi5Qv5vroFiqKGopiw  AEx2SYEUJmTxVVB18LlCwA   \n",
       "1  n6QzIUObkYshz4dz2QRJTw  bv2nCi5Qv5vroFiqKGopiw  VR6GpWIda3SfvPC-lg9H3w   \n",
       "2  MV3CcKScW05u5LVfF6ok0g  bv2nCi5Qv5vroFiqKGopiw  CKC0-MOWMqoeWf6s-szl8g   \n",
       "3  IXvOzsEMYtiJI0CARmj77Q  bv2nCi5Qv5vroFiqKGopiw  ACFtxLv8pGrrxMm6EgjreA   \n",
       "4  L_9BTb55X0GDtThi6GlZ6w  bv2nCi5Qv5vroFiqKGopiw  s2I_Ni76bjJNK9yG60iD-Q   \n",
       "\n",
       "   stars        date                                               text  \\\n",
       "0      5  2016-05-28  Super simple place but amazing nonetheless. It...   \n",
       "1      5  2016-05-28  Small unassuming place that changes their menu...   \n",
       "2      5  2016-05-28  Lester's is located in a beautiful neighborhoo...   \n",
       "3      4  2016-05-28  Love coming here. Yes the place always needs t...   \n",
       "4      4  2016-05-28  Had their chocolate almond croissant and it wa...   \n",
       "\n",
       "   useful  funny  cool  \n",
       "0       0      0     0  \n",
       "1       0      0     0  \n",
       "2       0      0     0  \n",
       "3       0      0     0  \n",
       "4       0      0     0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data =  pd.read_csv(r'yelp_review.csv',encoding = \"utf8\",keep_default_na=False,nrows=200000)\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite://', echo=False)\n",
    "data.to_sql('yelp_reviews',con=engine)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Super simple place but amazing nonetheless. It...\n",
       "1    Small unassuming place that changes their menu...\n",
       "2    Lester's is located in a beautiful neighborhoo...\n",
       "3    Love coming here. Yes the place always needs t...\n",
       "4    Had their chocolate almond croissant and it wa...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = data[:45000][\"text\"]\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Super', 'simple', 'place', 'amazing', 'nonetheless', 'around', 'since', '30s', 'still', 'serve', 'thing', 'started', 'bologna', 'salami', 'sandwich', 'mustard', 'Staff', 'helpful', 'friendly']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def tokenize_reviews(review):\n",
    "    rev = [char for char in review if char not in string.punctuation]\n",
    "    rev = ''.join(rev)\n",
    "    \n",
    "    return [word for word in rev.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "print(tokenize_reviews(reviews[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_tokens = []\n",
    "dataset = []\n",
    "for review in reviews:\n",
    "    if len(review) > 10:\n",
    "        rev_tokens.append(tokenize_reviews(review))\n",
    "        dataset.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New', 'town', 'wasnt', 'sure', 'store', 'would', 'satisfyso', 'went', 'convenience', 'Smiths', 'small', 'shopping', 'centerstrip', 'mall', 'kitty', 'corner', 'hotel', 'Best', 'Western', 'Ive', 'twice', 'week', 'lucked', 'times', 'great', 'parking', 'Unfamiliar', 'layout', 'store', 'simply', 'started', 'one', 'end', 'worked', 'way', 'side', 'nice', 'wine', 'selection', 'conveniently', 'located', 'next', 'fancy', 'cheese', 'area', 'Smiths', 'pretty', 'much', 'standard', 'grocery', 'store', 'produce', 'deli', 'bakery', 'grocery', 'health', 'beauty', 'oh', 'pharmacy', 'somewhat', 'confused', 'random', 'Kroger', 'items', 'display', 'throughout', 'store', 'inquired', 'clearance', 'near', 'expired', 'items', 'Kroger', 'owns', 'Smiths', 'pleasantly', 'surprised', 'able', 'use', 'Kroger', 'plus', 'card', 'applicable', 'discounts', 'cashier', 'first', 'time', 'warm', 'welcoming', 'wished', 'best', 'new', 'home', 'breath', 'fresh', 'air', 'someone', 'friendly', 'wait', 'enjoy', 'farmers', 'markets', 'everyday', 'stuff', 'Smiths']\n"
     ]
    }
   ],
   "source": [
    "print(rev_tokens[44998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r'pos_words.txt')\n",
    "positive  = file.read()\n",
    "positive = positive.lower()\n",
    "file = open(r'neg_words.txt')\n",
    "negative  = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_score(token):\n",
    "    score = []\n",
    "    for word in token:\n",
    "        if word in positive:\n",
    "            score.append(1)\n",
    "        elif word in negative:\n",
    "            score.append(-1)\n",
    "        else:\n",
    "            score.append(0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_scores = []\n",
    "for token in rev_tokens:\n",
    "    rev_scores.append(assign_score(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14913 14465 15621\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "labels = []\n",
    "pos = neg = neut = 0         \n",
    "for score in rev_scores:\n",
    "    if score:\n",
    "        val =  mean(score)\n",
    "        if val > 0.29:\n",
    "            labels.append(1)\n",
    "            pos += 1\n",
    "        elif 0.212 <= val <= 0.29:\n",
    "            labels.append(0)\n",
    "            neut += 1\n",
    "        else:\n",
    "            labels.append(-1)\n",
    "            neg += 1\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "print(pos,neg,neut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(dataset,labels,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...ty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer(analyzer = 'word',lowercase = True,stop_words='english')),\n",
    "               ('tfidf', TfidfTransformer(smooth_idf=True)),\n",
    "               ('clf', LogisticRegression(penalty='l2',solver='newton-cg',multi_class='multinomial')),\n",
    "              ])\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67022222 0.66148148 0.66162963 0.65837037 0.65357831]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(nb, x_train,y_train , cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6728"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nb.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.71      0.71      3615\n",
      "           0       0.56      0.55      0.56      3835\n",
      "           1       0.74      0.76      0.75      3800\n",
      "\n",
      "   micro avg       0.67      0.67      0.67     11250\n",
      "   macro avg       0.67      0.67      0.67     11250\n",
      "weighted avg       0.67      0.67      0.67     11250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_pred = nb.predict(x_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "counter = []\n",
    "counter = engine.execute(\"SELECT COUNT(*) AS count,business_id FROM yelp_reviews GROUP BY business_id\").fetchall()\n",
    "rest = heapq.nlargest(10,counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "correct = 0\n",
    "for count,id in rest:\n",
    "    data_base = []\n",
    "    stars = []\n",
    "    prediction = \"\"\n",
    "    data_base = engine.execute(\"SELECT text from yelp_reviews where business_id = ?\",(id)).fetchall()\n",
    "    stars = engine.execute(\"SELECT stars as INTEGER from yelp_reviews where business_id = ?\",(id)).fetchall()\n",
    "    new_db = []\n",
    "    stars_db = []\n",
    "    for data in data_base:\n",
    "        new_db.append(str(data))\n",
    "\n",
    "    for star in stars:\n",
    "        stars_db.append(star[0])\n",
    "        \n",
    "    ypred = nb.predict(new_db)\n",
    "    y_pred_new = []\n",
    "    for pred in ypred:\n",
    "        if pred == 0:\n",
    "            y_pred_new.append(3.5)\n",
    "        elif pred == -1:\n",
    "            y_pred_new.append(1.5)\n",
    "        else:\n",
    "            y_pred_new.append(5)\n",
    "        \n",
    "#         print(y_pred_new)\n",
    "    predicted = mean(y_pred_new)\n",
    "    actual = mean(stars_db)\n",
    "    if abs(predicted - actual) < 0.7:\n",
    "        prediction = \"correct\"\n",
    "        correct += 1\n",
    "    else:\n",
    "        prediction = \"wrong\"\n",
    "    results.append([predicted,actual,id,prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Predicted |   Actual | Business_id            | Result   |\n",
      "|-------------+----------+------------------------+----------|\n",
      "|     3.31151 |  3.63095 | RESDUcs7fIiihp38-d6_6g | correct  |\n",
      "|     3.46875 |  4.11667 | 4JNXUYY8wbaaDmk3BPzlWw | correct  |\n",
      "|     3.369   |  3.71616 | K7lWdNUhCbcnEvI0NhGewg | correct  |\n",
      "|     3.13636 |  3.9798  | cYwJA2A6I12KNkm2rtXd5g | wrong    |\n",
      "|     2.97135 |  4.27083 | DkYS3arLOhA8si5uUEmHOw | wrong    |\n",
      "|     3.01453 |  3.90116 | f4x1YBxkLrZg652xt2KR5g | wrong    |\n",
      "|     2.73052 |  3.9026  | 5LNZ67Yw9RD6nf4_UhXOjw | wrong    |\n",
      "|     3.02632 |  3.40132 | SMPbvZLSMMb7KU76YNYMGg | correct  |\n",
      "|     3.21812 |  3.44295 | ujHiaprwCQ5ewziu0Vi9rw | correct  |\n",
      "|     3.12847 |  3.61806 | 2weQS-RnoOBhb1KsHKyoSQ | correct  |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(results,headers=['Predicted', 'Actual', 'Business_id','Result'], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
